{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical Part\n",
    "## 1) Hypothesis Testing – The problem of multiple comparisons [5 points]\n",
    "Experimentation in AI often happens like this: \n",
    "Modify/Build an algorithm\n",
    "Compare the algorithm to a baseline by running a hypothesis test.\n",
    "If not significant, go back to step A\n",
    "If significant, start writing a paper. \n",
    "How many hypothesis tests, m, does it take to get to (with Type I error for each test = α):\n",
    "\n",
    "a) P(mth experiment gives significant result | m experiments lacking power to reject H0)?\n",
    "\n",
    "b) P(at least one significant result | m experiments lacking power to reject H0)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "a) If all m experiments lack the power reject the null hypothesis, we still assume that the results come from the probability distribution of H0. The probability of a significant result is given by the probability mass to the right of the critical value, corrected as the family-wise error rate.\n",
    " \n",
    "P(mth experiment gives significant result | m experiments lacking power to reject H0) = $$1 - (1-\\alpha)^m$$\n",
    "\n",
    "b) The probability of finding at least one significant result is the complement of finding no significant results.\n",
    "\n",
    "P(at least one significant result | m experiments lacking power to reject H0) =\n",
    "\n",
    "$$1 - (1-\\alpha)^m$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Bias and unfairness in Interleaving experiments [10 points]\n",
    "\n",
    "Balance interleaving has been shown to be biased in a number of corner cases. An example was given during the lecture with two ranked lists of length 3 being interleaved, and a randomly clicking population of users that resulted in algorithm A winning ⅔ of the time, even though in theory the percentage of wins should be 50% for both algorithms. Can you come up with a situation of two ranked lists of length 3 and a distribution of clicks over them for which Team-draft interleaving is unfair to the better algorithm?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical part\n",
    "## Step 1: Simulate Rankings of Relevance for E and P (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of possible ranking pairs:  58806\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    " \n",
    "def generate_ranking_pairs(grades, rank_len):\n",
    "    \"\"\" Generates all possible ranking pairs, excluding pairs of \n",
    "        equal rankings\n",
    "\n",
    "    Args:\n",
    "        grades (list): Possible grades in ranking.\n",
    "        rank_len (int): Length of ranking pairs.\n",
    "\n",
    "    Returns:\n",
    "        generator: All possible ranking pairs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # generate all possible rankings\n",
    "    rankings = product(grades, repeat=rank_len)\n",
    "    # generate all possible pairs of rankings\n",
    "    pairs = product(rankings, repeat=2)    \n",
    "    # exclude pairs of equal rankings\n",
    "    pairs = filter(lambda pair: pair[0] != pair[1], pairs)\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "grades = ['HR', 'R', 'N']\n",
    "rank_len = 5\n",
    "\n",
    "ranking_pairs = list(generate_ranking_pairs(grades, rank_len))\n",
    "print('Number of possible ranking pairs: ', len(ranking_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Implement Evaluation Measures (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_precision(rankings):    \n",
    "    \"\"\"Calculates Average Precision (AP) = Average of precisions at relevant documents\n",
    "\n",
    "    Args:\n",
    "        rankings (list): ranked result of query.\n",
    "\n",
    "    Returns:\n",
    "        float: The average precision of rankings.\n",
    "    \"\"\"\n",
    "    relevant = 0\n",
    "    numerator = 0\n",
    "    for rank, rel in enumerate(rankings):\n",
    "        rank += 1\n",
    "        if rel == 'R' or rel == 'HR':\n",
    "            relevant += 1\n",
    "            numerator += relevant/rank\n",
    "    return numerator/len(rankings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores for relevance that are used are 0, 1 and 5 for N, R and HR respectively (equal to example in slides).\n",
    "\n",
    "The nDCG@k measures requires the total number of relevant and highly relevant documents in the entire collection. Since\n",
    "for this dummy example there does not really exist a corpus, another approach is required:\n",
    "\n",
    "def nDCGk is feeded a ranking of length 5 (one of the permutations created in Step 1). This list of five is treated\n",
    "as the corpus. The list consisting of the first k elements is seen as the result of a query q, and the DCGk of this\n",
    "list is calculated by def DCGk. To find the perfect ranking (for normalization), the corpus list is sorted (descending)\n",
    "and the DCGk of the top k elements of the resulting list is calculated. The result is then used for normalization \n",
    "in def nDCGk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def DCGk(rankings):\n",
    "    \"\"\"Calculates Discounted Cumulative Gain (DCG)\n",
    "\n",
    "    Args:\n",
    "        rankings (list): ranked result of query.\n",
    "\n",
    "    Returns:\n",
    "        float: The discounted cumulative gain.\n",
    "    \"\"\"\n",
    "    discounted_gain = 0\n",
    "    for rank, rel in enumerate(rankings):\n",
    "        rank += 1\n",
    "        gain = (2**rel)-1\n",
    "        discount = 1/math.log(rank+1,2)    \n",
    "        discounted_gain += gain*discount        \n",
    "    return discounted_gain\n",
    "\n",
    "def nDCGk(rankings, k=3):\n",
    "    \"\"\"Calculates Normalized Discounted Cumulative Gain at rank k (nDCG@k)\n",
    "\n",
    "    Args:\n",
    "        rankings (list): ranked result of query. (treated as corpus)\n",
    "        k (int): rank k. Value of 3 is used if no argument is given.\n",
    "\n",
    "    Returns:\n",
    "        float: The normalized discounted gain at rank k.\n",
    "    \"\"\"\n",
    "    # translate relevance to corresponding score for calculations\n",
    "    rankings = [5 if x is 'HR' else 1 if x is 'R' else 0 for x in rankings]\n",
    "    # calculate discounted gain for top k\n",
    "    DCG = DCGk(rankings[:k])\n",
    "    # sort all relevant documents (descending) in the corpus by their \n",
    "    # relative relevance to find best possible DCG result (perfect ranking)\n",
    "    perfect_DCG = DCGk(sorted(rankings, reverse=True)[:k])\n",
    "    # normalize discounted_gain by this result\n",
    "    if perfect_DCG == 0:\n",
    "        return 0\n",
    "    return DCG/perfect_DCG\n",
    "\n",
    "#nDCGk(ranking_pairs[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5078201293945312"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ERR(rankings, k=5):\n",
    "    \"\"\"Computes the Expected Reciprocal Rank (ERR) metric in linear time. Based on paper by Chapelle et al.\n",
    "\n",
    "    Args:\n",
    "        rankings (list): ranked result of query.\n",
    "        k (int): rank k. Value of 5 is used if no argument is given.\n",
    "\n",
    "    Returns:\n",
    "        float: the Expected Reciprocal Rank (ERR).\n",
    "    \"\"\"\n",
    "    # translate relevance to corresponding score for calculations\n",
    "    rankings = [5 if x is 'HR' else 1 if x is 'R' else 0 for x in rankings]\n",
    "    p = 1.0\n",
    "    err = 0.0\n",
    "    for rank, rel in enumerate(rankings[:k]):\n",
    "        rank += 1\n",
    "        R = ((2**rel)-1) / (2**max(rankings))\n",
    "        err += p*(R/rank)\n",
    "        p *= 1-R\n",
    "    return err\n",
    "\n",
    "ERR(ranking_pairs[100][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Calculate the delta measure (0 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delta_measure(P, E, measure):\n",
    "    \"\"\"Computes the delta of P and E for average precision, nDCG@k or ERR.\n",
    "\n",
    "    Args:\n",
    "        P (list): ranked result of production algorithm.\n",
    "        E (list): ranked result of experimental algorithm.\n",
    "        measure (string): measure to be calculated (average precision, nDCGk, ERR)\n",
    "\n",
    "    Returns:\n",
    "        float: delta of E and P. If < 0, E does not outperform P.\n",
    "    \"\"\"\n",
    "    if measure == 'average precision':\n",
    "        P_measure = average_precision(P)\n",
    "        E_measure = average_precision(E)\n",
    "    elif measure == 'nDCGk':\n",
    "        P_measure = nDCGk(P)\n",
    "        E_measure = nDCGk(E)\n",
    "    elif measure == 'ERR':\n",
    "        P_measure = ERR(P)\n",
    "        E_measure = ERR(E)\n",
    "    \n",
    "    return E_measure - P_measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Implement Interleaving (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def interleave(ranking_A, ranking_B):\n",
    "    \"\"\"\n",
    "    Interleaves rankings from two different ranking algorithms into \n",
    "    one ranking based on Team Draft Interleaving. Both rankings are\n",
    "    assumed to have equal length.\n",
    "    \n",
    "    Args:\n",
    "        ranking_A (list): Ranking of algorithm A.\n",
    "        ranking_B (list): Ranking of algorithm B.\n",
    "        \n",
    "    Returns:\n",
    "        (Dict): Dict containing two lists: the interleaved ranking and the origins.\n",
    "    \"\"\"\n",
    "    ranking_I = []\n",
    "    origins = []\n",
    "    i = 0\n",
    "    while len(ranking_I) < len(ranking_A):\n",
    "        # A wins\n",
    "        if randint(0,1) == 0:\n",
    "            origins += [0,1]\n",
    "            ranking_I.append(ranking_A[i])\n",
    "            ranking_I.append(ranking_B[i])\n",
    "        # B wins\n",
    "        else:\n",
    "            origins += [1,0]\n",
    "            ranking_I.append(ranking_B[i])\n",
    "            ranking_I.append(ranking_A[i])\n",
    "        i += 1\n",
    "    if len(ranking_I) > len(ranking_A):\n",
    "        ranking_I = ranking_I[0:-1]\n",
    "        origins = origins[0:-1]\n",
    "    return {'ranking': ranking_I, 'origins': origins}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'N', 'R', 'HR', 'N'] ['R', 'HR', 'N', 'N', 'R']\n",
      "['R', 'N', 'HR', 'N', 'N']\n"
     ]
    }
   ],
   "source": [
    "ranking_A = ['N','N','R','HR','N']\n",
    "ranking_B = ['R','HR','N','N','R']\n",
    "interleaved_ranking = interleave(ranking_A, ranking_B)\n",
    "print(ranking_A, ranking_B)\n",
    "print(interleaved_ranking['ranking'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Implement User Clicks Simulation (15 points)\n",
    "### Random Click Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import uniform\n",
    "\n",
    "class RandomClickModel:\n",
    "    '''\n",
    "    Implements a Random Click Model. This model decides to click on a document\n",
    "    with a probability P_click without taking anything else into account. P_click\n",
    "    is learned from a click log. The default click log is from Yandex.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, click_log_path = 'YandexRelPredChallenge.txt'):\n",
    "        self.P_click = self.train(click_log_path)\n",
    "        \n",
    "    def train(self, click_log_path):\n",
    "        '''\n",
    "        Estimates the only parameter P_click of the Random Click Model using a click log\n",
    "        by dividing the total amount of clicks by the total amount of shown documents.\n",
    "\n",
    "        Args:\n",
    "            click_log_path (String): Location of the click log.\n",
    "\n",
    "        Return:\n",
    "            Float: The P_click parameter used to decide whether to click on a document.\n",
    "\n",
    "        '''\n",
    "        shown_docs = 0\n",
    "        clicks = 0\n",
    "        with open(click_log_path,'r') as f:\n",
    "            for line in f:\n",
    "                line = line.split()\n",
    "\n",
    "                # Count all shown docs\n",
    "                if line[2] == 'Q':\n",
    "                    shown_docs += len(line)-5\n",
    "\n",
    "                # Count all clicks\n",
    "                else:\n",
    "                    clicks += 1\n",
    "        P_click = clicks/float(shown_docs)\n",
    "        return P_click\n",
    "\n",
    "    def predictProb(self, ranking):\n",
    "        '''\n",
    "        Generates the probability for each document in a ranking to be clicked on\n",
    "        based on a Random Click Model.\n",
    "\n",
    "        Args:\n",
    "            ranking (List): List of ranked documents represented by relevance.\n",
    "\n",
    "        Return:\n",
    "            List: A list of click probabilities for each document in the ranking.\n",
    "        '''\n",
    "        click_probabilities = []\n",
    "        for doc in ranking:\n",
    "            click_probabilities.append(self.P_click)\n",
    "        return click_probabilities\n",
    "\n",
    "    def assignClicks(self, ranking):\n",
    "        '''\n",
    "        Based on their click probabilities, either do or do not assign a click to each document.\n",
    "\n",
    "        Args:\n",
    "            ranking_probabilities (List): A list of click probability and document tuples.\n",
    "            P_click (float): Probability used to decide whether to click on a document.\n",
    "\n",
    "        Return:\n",
    "            List: A list representing clicks with 1's on documents in ranking with the same index.\n",
    "        '''\n",
    "        click_probabilities = self.predictProb(ranking)\n",
    "        clicks = []\n",
    "        for prob in click_probabilities:\n",
    "            if uniform(0,1) < prob:\n",
    "                clicks.append(1)\n",
    "            else:\n",
    "                clicks.append(0)\n",
    "        return clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "ranking_I = ['HR','R','HR','N','R']\n",
    "clicks = RandomClickModel().assignClicks(ranking_I)\n",
    "print(clicks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Dependent Click Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class SdcmClickModel():\n",
    "    \"\"\" Implements a Simple Dependent Click Model (SDCM). Generates clicks starting\n",
    "        from the first rank, and stochastically decides if a clicked result is \n",
    "        satisfactory, using probabilities trained on a click log. If the result was \n",
    "        not satisfactory, the next result is examined, and then clicked with a \n",
    "        probability dependent on the corresponding relevance label. The probabilities\n",
    "        for each of the relevance labels are taken from the book \"Click Models for \n",
    "        Web Search\".\n",
    "    \n",
    "    Args:\n",
    "        click_log_path (str): Location of the click log.\n",
    "        attr_model (str): Model used for attractiveness parameters\n",
    "                            (perfect/navigational/informative)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"Click model attractiveness parameters\"\"\"\n",
    "    attr_perf = {'HR':1.0, 'R':0.5, 'N':0.0}\n",
    "    attr_nav = {'HR':0.95, 'R':0.5, 'N':0.05}\n",
    "    attr_inf = {'HR':0.9, 'R':0.7, 'N':0.4} \n",
    "    \n",
    "    def __init__(self, click_log_path='YandexRelPredChallenge.txt', attr_model='nav'):\n",
    "        self.click_log_path = click_log_path\n",
    "        if attr_model == 'nav':\n",
    "            self.attr_model = SdcmClickModel.attr_nav\n",
    "        elif attr_model == 'perf':\n",
    "            self.attr_model = SdcmClickModel.attr_perf            \n",
    "        elif attr_model == 'inf':\n",
    "            self.attr_model = SdcmClickModel.attr_inf\n",
    "        else:\n",
    "            raise ValueError('The attractiveness model \"{}\" is not available.' \\\n",
    "                            ' Choose from \"nav\", \"perf\" or \"inf\".'.format(attr_model))\n",
    "        self.params = self.learnParams()\n",
    "            \n",
    "    def learnParams(self):\n",
    "        \"\"\" Learns parameters for simple dependent click model.\n",
    "\n",
    "        Returns:\n",
    "            dict: Learnt click model parameters.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        with open(self.click_log_path,'r') as f:\n",
    "            # global rank click counter\n",
    "            rank_counter = Counter()\n",
    "            # counter for clicks on consecutive ranks\n",
    "            pair_counter = Counter()\n",
    "            # rank counter that resets for each new session\n",
    "            temp_counter = Counter()\n",
    "            result_pages = []\n",
    "            for line in f:\n",
    "                line = line.split()\n",
    "                time_passed = line[1]\n",
    "                if time_passed == '0':\n",
    "                    result_pages = []\n",
    "                    for rank, _ in temp_counter.items():\n",
    "                        prev_idx = int(rank)-1\n",
    "                        if temp_counter[prev_idx] > 0:\n",
    "                            # increase counter if previous url was clicked\n",
    "                            pair_counter[prev_idx] += 1\n",
    "                    temp_counter = Counter()\n",
    "                if line[2] == 'Q':\n",
    "                    result_pages.append(line[5:])\n",
    "                else:\n",
    "                    url = line[3]\n",
    "                    for results in result_pages:\n",
    "                        try:\n",
    "                            rank = results.index(url)\n",
    "                            rank_counter[rank] += 1\n",
    "                            temp_counter[rank] += 1\n",
    "                            break\n",
    "                        except:\n",
    "                            pass\n",
    "        lambdas = {r+1:pair_counter[r]/rank_counter[r] for r in pair_counter.keys()}\n",
    "        return lambdas\n",
    "\n",
    "    \n",
    "    def attrProbs(self, ranking):\n",
    "        \"\"\" Assigns attractiveness probabilities for list of relevance labels.\n",
    "\n",
    "        Args:\n",
    "            ranking (list): Ranked list of relevance labels.\n",
    "\n",
    "        Returns:\n",
    "            list: List of attractiveness probabilities corresponding with ranking.\n",
    "\n",
    "        \"\"\"\n",
    "        probs = [self.attr_model[label] for i, label in enumerate(ranking)]\n",
    "        return probs\n",
    "\n",
    "    def assignClicks(self, ranking):\n",
    "        \"\"\" Assigns clicks based on attractiveness and satisfactoriness probabilities.\n",
    "\n",
    "        Args:\n",
    "            ranking (list): Ranked list of relevance labels.\n",
    "\n",
    "        Returns:\n",
    "            list: Assigned clicks.\n",
    "\n",
    "        \"\"\"\n",
    "        probs = self.attrProbs(ranking)\n",
    "        \n",
    "        clicks = []  \n",
    "        for i in range(len(probs)):\n",
    "            if i == 0:\n",
    "                # for first result, click probability equals attractiveness\n",
    "                p_click = probs[i]\n",
    "            else:\n",
    "                prev_click = clicks[i-1]\n",
    "                if prev_click == 1:\n",
    "                    p_satisf = 1 - self.params[i]\n",
    "                    # stochastically decide satisfactoriness    \n",
    "                    outcome = random()\n",
    "                    if outcome < p_satisf:\n",
    "                        # when the clicked result was satisfactory, stop\n",
    "                        clicks += ([0] * (len(probs) - len(clicks)))\n",
    "                        break\n",
    "                    else:\n",
    "                        p_click = probs[i]\n",
    "                else:\n",
    "                    p_click = probs[i]\n",
    "            # stochastically decide click \n",
    "            outcome = random()\n",
    "            if outcome < p_click:\n",
    "                clicks.append(1)\n",
    "            else: clicks.append(0)\n",
    "        return clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "ranking = ['HR', 'R', 'R', 'N', 'HR', 'N', 'R']\n",
    "clicks = SdcmClickModel().assignClicks(ranking)\n",
    "print(clicks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Simulate Interleaving Experiment (10 points)\n",
    "Having implemented the click models, it is time to run the simulated experiment.\n",
    "For each of interleaved ranking run N simulations for each one of the click models implemented and measure the proportion p of wins for E.\n",
    "(Note 7: Some of the models above include an attractiveness parameter 𝑎uq. Use the relevance label to assign this parameter by setting 𝑎uq for a document u in the ranked list accordingly. (See Click Models for Web Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate_experiment(ranked_pairs, N, click_model):\n",
    "    '''\n",
    "    Simulate an on-line user experiment to compare the ranking performance\n",
    "    of two algorithms, P and E.\n",
    "    \n",
    "    Args:\n",
    "        interleaved_rankings (List): A list containing interleaved rankings and their origins\n",
    "        N (int): The number of simulations to run per click model.\n",
    "        click_model (object): An object representing a click model able to assign clicks to a ranking.\n",
    "        \n",
    "    Returns:\n",
    "        float: The proportion p of wins for algorithm E (1) over P (0)\n",
    "    '''\n",
    "    \n",
    "    # Obtain interleaved rankings\n",
    "    interleaved_rankings = []\n",
    "    for ranking_A, ranking_B in ranked_pairs:\n",
    "        interleaved_rankings.append(interleave(ranking_A, ranking_B))\n",
    "    \n",
    "    # Simulate N experiments\n",
    "    clicks_total = 0\n",
    "    clicks_E = 0\n",
    "    for i in range(N):\n",
    "        for interleaved_ranking in interleaved_rankings:\n",
    "            ranking = interleaved_ranking['ranking']\n",
    "            origins = interleaved_ranking['origins']\n",
    "    \n",
    "            # Simulate clicks\n",
    "            clicks = click_model.assignClicks(ranking)\n",
    "            \n",
    "            # Store number of clicks for E as well as total number of clicks.\n",
    "            for click, origin in zip(clicks,origins):\n",
    "                clicks_total += click\n",
    "                if click + origin == 2:\n",
    "                    clicks_E += 1\n",
    "    return clicks_E/float(clicks_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49949505303841396\n"
     ]
    }
   ],
   "source": [
    "# Obtain ranked pairs from algorithm P and E\n",
    "grades = ['HR', 'R', 'N']\n",
    "rank_len = 5\n",
    "ranked_pairs = generate_ranking_pairs(grades, rank_len)\n",
    "\n",
    "# Specify simulation parameters\n",
    "N = 10\n",
    "click_log_path = 'YandexRelPredChallenge.txt'\n",
    "click_model = RandomClickModel(click_log_path)\n",
    "\n",
    "# Compute win ratio of algorithm E (1) over P (0)\n",
    "win_ratio = simulate_experiment(ranked_pairs, N, click_model)\n",
    "print(win_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 7: Results and Analysis (30 points)\n",
    "Compare the results of the offline experiments (i.e. the values of the 𝛥measure) with the results of the online experiment (i.e. proportion of wins), analyze them and reach your conclusions regarding their agreement.\n",
    "Use easy to read and comprehend visuals to demonstrate the results;\n",
    "\n",
    "Analyze the results on the basis of\n",
    "- the evaluation measure used,\n",
    "- the interleaving method used,\n",
    "- the click model used.\n",
    "\n",
    "Report and ground your conclusions.\n",
    "(Note 8: This is the place where you need to demonstrate your deeper understanding of what you have implemented so far; hence the large number of points assigned. Make sure you clearly do that so that the examiner of your work can grade it accordingly.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Offline Evaluation ####\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNej/A3QyzaYjTG2vAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f59842a84e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD99A/twidgG8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f59842a4b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Online Evaluation ####\n",
      "0.4979951762879665\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Obtain ranked pairs from algorithm P and E\n",
    "grades = ['HR', 'R', 'N']\n",
    "rank_len = 5\n",
    "ranked_pairs = list(generate_ranking_pairs(grades, rank_len))\n",
    "\n",
    "# Run offline evaluation experiments using the three different\n",
    "# evaluation metrics: average precision, nDCGk and ERR\n",
    "delta_AP, delta_nDCGk, delta_ERR = [], [], []\n",
    "for P, E in ranked_pairs:\n",
    "    delta_AP.append(delta_measure(P,E,'average precision'))\n",
    "    delta_nDCGk.append(delta_measure(P,E,'nDCGk'))\n",
    "    delta_ERR.append(delta_measure(P,E,'ERR'))\n",
    "\n",
    "# Compute win ratio's per evaluation metric\n",
    "delta_AP = np.array([x for x in delta_AP if x > 0])\n",
    "delta_nDCGk = np.array([x for x in delta_nDCGk if x > 0])\n",
    "delta_ERR = np.array([x for x in delta_ERR if x > 0])\n",
    "n = len(ranked_pairs)\n",
    "win_ratio_AP = len(delta_AP)/n\n",
    "win_ratio_nDCGk = len(delta_nDCGk)/n\n",
    "win_ratio_ERR = len(delta_ERR)/n\n",
    "\n",
    "# Plot win ratio's and average deltas\n",
    "print('#'*4, 'Offline Evaluation', '#'*4)\n",
    "plt.bar([0,1,2],[win_ratio_AP, win_ratio_ERR, win_ratio_nDCGk])\n",
    "plt.title('Win ratio\\'s of AR, nDCGk and ERR')\n",
    "plt.show()\n",
    "\n",
    "plt.bar([0,1,2],[np.mean(delta_AP), np.mean(delta_nDCGk), np.mean(delta_ERR)])\n",
    "plt.title('Average delta\\'s of AR, nDCGk and ERR')\n",
    "plt.show()\n",
    "\n",
    "# Run online experiments using team draft interleaving and \n",
    "# three different click models.  \n",
    "N = 10\n",
    "click_log_path = 'YandexRelPredChallenge.txt'\n",
    "click_model = RandomClickModel(click_log_path)\n",
    "\n",
    "# Compute win ratio of algorithm E (1) over P (0)\n",
    "win_ratio = simulate_experiment(ranked_pairs, N, click_model)\n",
    "\n",
    "print('#'*4, 'Online Evaluation', '#'*4)\n",
    "\n",
    "print(win_ratio)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
